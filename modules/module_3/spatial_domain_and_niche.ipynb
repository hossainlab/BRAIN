{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niche reconstruction and spatial domain detection\n",
    "\n",
    "In this notebook we will cover:\n",
    "\n",
    "1. Graph construction and analysis of spatial transcriptomics data using Squidpy\n",
    "2. CellCharter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and ML imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# single-cell imports\n",
    "import squidpy as sq\n",
    "import scanpy as sc\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the Xenium AD dataset from the previous notebooks here.\n",
    "\n",
    "As a reminder the dataset consists of 6 coronal mouse brain slices from 2 different conditions (wildtype - ctrl vs TgCRND8 - AD) across 3 timepoints. We have annotated cell types that are available in  `adata.obs['cell_types']`. Please note that these annotation are not perfect. For example, there are quite some cells that could not be assigned to a cell type (NaN or \"unkown\"). We used leiden clustering and marker genes reported in [this](https://pages.10xgenomics.com/rs/446-PBO-704/images/10x_LIT000210_App-Note_Xenium-In-Situ_Letter_Digital.pdf) document for the annotation (check corresponding jupyter notebook). \n",
    "\n",
    "In this practical we aim to understand the differences of the mouse brain between the two conditions and across the timepoints using niches and spatial domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/francesca.drummer/Documents/1_Projects/GSCN workshop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adata\n",
    "adata = sc.read_h5ad(Path(PATH, 'xenium_mouse_ad_annotated_rotated_domain.h5ad'))\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from 'split', 'fov', and 'condition'\n",
    "df = adata.obs[['condition', 'time', 'batch_key']]\n",
    "value_counts = pd.DataFrame(df.values, columns=df.columns).value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cell_types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cell neighborhood detection via graph construction\n",
    "\n",
    "Spatial transcriptomics data can be represented as graphs with cells as nodes and edges as relations. Depending on the technology (imaging-based or sequencing-based) different assumptions can be made for the graph structure. \n",
    "Here we will explore graph construction and cell neighborhood analysis using the squidpy `sq.gr.spatial_neighbors` module on imaging-based data. \n",
    "\n",
    "*Information for graph reconstruciton for sequencing-based data can be found [here](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_spatial_neighbors.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image-based technologies we construct a graph with `coord_type=generic`, meaning that the nodes / cells will preserve their spatial location and will not be re-arranged in a spatial grid. For generic graph approaches we can choose to set a fixed radius `radius` or number of neighbors to connect to (`n_neighs`).\n",
    "\n",
    "Below we try both graph construction methods and give them a different `key` to add to the `adata` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cell_types_colors' in adata.uns:\n",
    "    del adata.uns['cell_types_colors']\n",
    "    \n",
    "sq.gr.spatial_neighbors(adata, n_neighs=5, coord_type=\"generic\", key_added = 'neighs_based_spatial')\n",
    "sq.pl.spatial_scatter(\n",
    "    adata,\n",
    "    shape=None,\n",
    "    library_key = 'sample',\n",
    "    color=[\"cell_types\"],\n",
    "    connectivity_key=\"neighs_based_spatial_connectivities\",\n",
    "    title=adata.obs['sample'].cat.categories,\n",
    "    ncols=3,\n",
    "    size = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, radius=0.2, coord_type=\"generic\", key_added = 'radius_based_spatial')\n",
    "sq.pl.spatial_scatter(\n",
    "    adata,\n",
    "    shape=None,\n",
    "    library_key = 'sample', \n",
    "    color=\"cell_types\",\n",
    "    connectivity_key=\"radius_based_spatial_connectivities\",\n",
    "    title=adata.obs['sample'].cat.categories,\n",
    "    ncols=3,\n",
    "    size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First differences across the graphs can be observed by visual inspection, e.i. the cells that are further away from the clear brain structures are connected in the clostest neighbor approach but unconnected in the radius-based approach. Some other differences are harder to observe like dependencies in the more dense connected regions. For this Squidpy provides a number of statistics to better the differences between the connectivities of cells.\n",
    "\n",
    "Using the cell type information we can formulate some hypothesis from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform downstream analysis you require a graph structure or radius that connects the cells of interest. For example, if you are interested in the communication between Microglia and Oligodendrocytes you need to set a radius such that the cell typer connections exists.\n",
    "\n",
    "<span style=\"color: red;\">**Task 1:** Compute the [interaction matrix](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_interaction_matrix.html) to understand differences between neighborhood and radius based graphs. Find an appropriate number of neighbors or radius that include sufficient connections between your cell types of interest.</span>\n",
    "\n",
    "Example questions to answer could be: What are the average number of connections per cell type? Which cell types tend to cluster together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.interaction_matrix(adata, cluster_key=\"cell_types\", connectivity_key=\"neighs_based_spatial\")\n",
    "sq.pl.interaction_matrix(adata, cluster_key=\"cell_types\", connectivity_key=\"neighs_based_spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Interaction matrix for radius based graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 2:** Try out some analysis from Squidpy to identify distinctions between the graphs e.i. using the [centrality score](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_centrality_scores.html) and [neighborhood enrichment](https://squidpy.readthedocs.io/en/stable/notebooks/examples/graph/compute_nhood_enrichment.html). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.centrality_scores(adata, cluster_key = \"cell_types\", connectivity_key = \"neighs_based_spatial\")\n",
    "sq.pl.centrality_scores(adata, cluster_key = \"cell_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.nhood_enrichment(adata, cluster_key=\"cell_types\", library_key = 'condition', connectivity_key = \"radius_based_spatial\")\n",
    "sq.pl.nhood_enrichment(\n",
    "    adata, cluster_key=\"cell_types\", method=\"average\", figsize=(5, 5)\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spatial Domain detection with CellCharter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import scanpy as sc\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import squidpy as sq\n",
    "import numpy as np\n",
    "import cellcharter as cc\n",
    "import os\n",
    "import logging\n",
    "logger = logging.getLogger('pytorch_lightning.utilities.rank_zero')\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.settings.seed = 12345\n",
    "scvi.settings.num_threads = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be cells with very low counts. We will filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_counts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dimensionality reduction\n",
    "\n",
    "First, we need to run the dimensionality reduction. We will use [scVI](https://docs.scvi-tools.org/en/latest/api/reference/scvi.model.SCVI.html) for this.\n",
    "\n",
    "Make sure that `adata.X` contains count data, as it is required by scVI. <br>\n",
    "In some tutorials you will see that the count data is stored in an AnnData layer called `counts`. Here we will use the `X` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameters of the neural network. Here we use 1 layer and an embedding size of 10.<br>\n",
    "These are very common parameters, but you can play with them to see how they affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    model = scvi.model.SCVI.load(os.path.join(PATH, 'scvi_model'), adata=adata)\n",
    "else:\n",
    "    model = scvi.model.SCVI(\n",
    "        adata,\n",
    "        n_layers=1,\n",
    "        n_latent=10,\n",
    "        use_layer_norm=\"both\",\n",
    "        use_batch_norm=\"none\",\n",
    "    )\n",
    "    model.train(early_stopping=True, enable_progress_bar=True, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the training has converged, we can plot the training history.<br>\n",
    "Here we is important to focus on the (validation) reconstruction loss. This shows how well the model is able to reconstruct the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(\n",
    "    model.history[f\"reconstruction_loss_train\"],\n",
    "    label=\"train\",\n",
    "    color=\"darkgreen\",\n",
    "    linewidth=1.25\n",
    ")\n",
    "plt.plot(\n",
    "    model.history[f\"reconstruction_loss_validation\"],\n",
    "    label=\"validation\",\n",
    "    color=\"firebrick\",\n",
    "    linewidth=1.25\n",
    "    )\n",
    "plt.legend()\n",
    "plt.title(\"reconstruction_loss\")  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the latent representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_scVI'] = model.get_latent_representation(adata).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Neighborhood aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, all the analyses have been done ignoring the spatial information. <br>\n",
    "Now we will use the spatial information to perform the clustering.\n",
    "\n",
    "First, we need to create a network where cells are connected if they are close to each other using the Delaunay triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, library_key='sample', coord_type='generic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample',\n",
    "    library_id=adata.obs['sample'].cat.categories[0],\n",
    "    color=\"sample\", \n",
    "    size=1, \n",
    "    figsize=(10,10),\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Delaunay triangulation generates very long edges for a few cells. <br>\n",
    "The most appropriate approach would be to estimate the most biologically relevant distance between cells and use it to remove the edges longer than that distance.\n",
    "\n",
    "A quick alternative solution is that, since those long edges are sort of outlines, the measure the 99th percentile of the edge lengths and remove the edges longer than that distance. <br>\n",
    "This process will lead to some isolated cells, but that's not a problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, library_key='sample', coord_type='generic', percentile=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample',\n",
    "    library_id=adata.obs['sample'].cat.categories[0],\n",
    "    color=\"sample\", \n",
    "    size=1, \n",
    "    figsize=(10,10),\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    ncols=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct the neighborhood aggregated representation by combining every cell's features with the ones of first 3 layers of neighbors.<br>\n",
    "We will use the scVI latent representation as features and the new features will be stored in `adata.obsm['X_cellcharter']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.aggregate_neighbors(adata, n_layers=3, use_rep='X_scVI', out_key='X_cellcharter_temp', sample_key='sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 3:** Given that `X_scVI` contains 10 features, how many features does `X_cellcharter` contain?<br>\n",
    "Guess the answer and then write the code to check it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cluster the cells and find their spatial domains.<br>\n",
    "We will use 18 clusters, we will see later why this is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = cc.tl.Cluster(n_clusters=18, random_state=12345)\n",
    "gmm.fit(adata, use_rep='X_cellcharter_temp')\n",
    "adata.obs['spatial_domain_temp'] = gmm.predict(adata, use_rep='X_cellcharter_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot domains and cell types back to back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spatial_domain_temp_colors' in adata.uns:\n",
    "    del adata.uns['spatial_domain_temp_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_temp\", \"cell_types\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Downstream analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last section was to show how CellCharter can be used to obtain spatial domains.\n",
    "\n",
    "However, to have an easier discussion and interpretation of the results, we want everyone to have the same results.\n",
    "\n",
    "Therefore, we will use the spatial domains computed in advance using the `ClusterAutoK` model that also runs the stability analysis to find the optimal number of clusters.\n",
    "The model has been computed using 3 layers of neighbors (it took 25 minutes on a GPU).\n",
    "\n",
    "We have to:\n",
    "1. load the features from the pretrained scvi model to generate the same features used by fitted `ClusterAutoK`\n",
    "2. aggregate the neighborhood features using the same number of layers as used by `ClusterAutoK` (3 layers of neighbors)\n",
    "3. load the `ClusterAutoK` model\n",
    "4. plot the stability curve\n",
    "5. look for the peak(s) to identify the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scvi.model.SCVI.load(os.path.join(PATH, 'scvi_model'), adata=adata)\n",
    "adata.obsm['X_scVI'] = model.get_latent_representation(adata).astype(np.float32)\n",
    "cc.gr.aggregate_neighbors(adata, n_layers=3, use_rep='X_scVI', out_key='X_cellcharter', sample_key='sample')\n",
    "\n",
    "autok = cc.tl.ClusterAutoK.load(Path(PATH, 'autok_l3'))\n",
    "cc.pl.autok_stability(autok)\n",
    "\n",
    "# If it takes too long also in this case, you can load the domain labels from the data folder\n",
    "# adata.obs['spatial_domain_18'] = pd.read_csv(Path(PATH, 'spatial_domains_cellcharter.csv'), index_col=0)['spatial_domain_18']\n",
    "# adata.obs['spatial_domain_18'] = adata.obs['spatial_domain_18'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see a clear single peak, but we can see that the highest stability is for 18 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['spatial_domain_18'] = autok.predict(adata, use_rep='X_cellcharter', k=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spatial_domain_18_colors' in adata.uns:\n",
    "    del adata.uns['spatial_domain_18_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_18\", \"cell_types\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the spatial domains, we can look at the cell type enrichment in each domain.\n",
    "\n",
    "This function measures the likelihood of a cell type being found in a domain compared to random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.enrichment(\n",
    "    adata,\n",
    "    group_key='spatial_domain_18',\n",
    "    label_key='cell_types',\n",
    ")\n",
    "cc.pl.enrichment(\n",
    "    adata,\n",
    "    group_key='spatial_domain_18',\n",
    "    label_key='cell_types',\n",
    "    dot_scale=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 4:**\n",
    "The [Allen Brain Atlas](https://atlas.brain-map.org/atlas?atlas=1&plate=100960076#atlas=1&plate=100960520&resolution=6.98&x=5512.001546223959&y=3967.997233072917&zoom=-2) provides images and annotation of mouse brain samples at multiple depths.<br><br>\n",
    "Choose one of the six samples, go to the atlas and try to find the image that better matches the regions shown by CellCharter.</span>\n",
    "\n",
    "<span style=\"color: red;\">1. Which of the 132 images is the closest one?</span><br>\n",
    "<span style=\"color: red;\">2. After identifying the closest image, try to match the domains obtained with the annotated regions in the atlas.</span><br>\n",
    "<span style=\"color: red;\">3. Do you find anatomical differences between the two conditions? are there differences in spatial domain compositions? Are there unique domains in one of the two conditions (Alzheimer vs wildtype)?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Focus, in particular on comparing samples from mice of the same age.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- If you find difference between the two samples, what do you think is the cause?</span><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 5:** Now, save the spatial domains corresponding to 9 and 23 clusters into the `adata.obs` column `spatial_domain_9` and `spatial_domain_23`.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(\n",
    "    adata, \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"spatial_domain_9\", \"spatial_domain_18\", \"spatial_domain_23\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(adata.obs['sample'].cat.categories, 3),\n",
    "    ncols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three levels of clustering form a sort of hierarchical structure.<br>\n",
    "9-cluster domains tend to separate into subdomains in the 18 clusters, and so on.\n",
    "\n",
    "<span style=\"color: red;\">**Task 6:** Go back to the Allen Brain Atlas and look if some of the hierarchical structure is reflected in the atlas.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to look at the shapes of the domains we obtained.\n",
    "\n",
    "We first find the local components of the domains.\n",
    "This is done by first finding the connected components of the spatial graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.connected_components(adata, cluster_key='spatial_domain_18', min_cells=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hackfix: squidpy's spatial_scatter has some issues with categorical data with NaNs.\n",
    "adata.obs['component_tmp'] = adata.obs['component'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'component_tmp_colors' in adata.uns:\n",
    "    del adata.uns['component_tmp_colors']\n",
    "\n",
    "sq.pl.spatial_scatter(\n",
    "    adata[(adata.obs['sample'].isin(['TgCRND8_17_9', 'TgCRND8_2_5']))], \n",
    "    shape=None, \n",
    "    library_key='sample', \n",
    "    color=[\"component_tmp\", \"spatial_domain_18\"], \n",
    "    size=1,\n",
    "    figsize=(10,10),\n",
    "    title=np.repeat(['TgCRND8_17_9', 'TgCRND8_2_5'], 2),\n",
    "    ncols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then draw a boundary around every component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.tl.boundaries(adata, alpha_start=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.pl.boundaries(adata, sample='wildtype_5_7', show_cells=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, by computing some shape metrics that we will use to compare the domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.tl.curl(adata)\n",
    "cc.tl.linearity(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shape metrics of one of the cortex layers, domain 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.pl.shape_metrics(adata, cluster_key='spatial_domain_18', figsize=(6,3), cluster_id=8, metrics=['curl', 'linearity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 7:** Look at the spatial domain 0.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Is it going to have lower, same or higher linearity than domain 8?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What about curl?</span>\n",
    "\n",
    "<span style=\"color: red;\">After you have answered, plot the shape metrics for domain 0 and check if it matches your expectations.</span>\n",
    "\n",
    "Tip: you can pass multiple cluster ids to `plot_shape_metrics` in the form of a list to plot multiple domains at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Task 8:** Look at spatial domain 12.</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What do you expect to see in terms of curl and linearity?</span><br>\n",
    "<span style=\"color: red;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- What about elongation?</span>\n",
    "\n",
    "<span style=\"color: red;\">After answering, compute the elongation and compare the shape metrics for domains 8 and 12.</span>\n",
    "\n",
    "You can check [CellCharter's documentation](https://cellcharter.readthedocs.io/en/latest/tools.html) for the elongation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Varrone, M., Tavernari, D., Santamaria-Martínez, A., Walsh, L. A. & Ciriello, G. CellCharter reveals spatial cell niches associated with tissue remodeling and cell plasticity. Nat Genet 56, 74–84 (2024).\n",
    "\n",
    "[2] Singhal, V. et al. BANKSY unifies cell typing and tissue domain segmentation for scalable spatial omics data analysis. Nat Genet 56, 431–441 (2024).\n",
    "\n",
    "[3] https://github.com/NBISweden/workshop-spatial/blob/main/labs/07b_spatial_domains.ipynb: Last access: 14.01.2025\n",
    "\n",
    "[4] [ELIXIR 2025 Spatial transcriptomics course](https://github.com/elixir-europe-training/ELIXIR-SCO-spatial-omics/blob/main/day_3/practical_4/workdir/p4_niche_domain.ipynb). Last access: 9.10.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
