---
title: "Module 16: Deep Learning in Single-Cell Genomics - Part 2"
subtitle: "Advanced Architectures: Graph Neural Networks and Transformers"
---

## Overview

Advanced deep learning architectures including graph neural networks (GNNs) and transformers are revolutionizing single-cell analysis, enabling new capabilities for cell-cell interaction modeling and foundation models.

::: {.callout-note}
## Learning Objectives

- Understand graph neural networks for cell-cell interactions
- Apply attention mechanisms to single-cell data
- Use transformer-based foundation models
- Implement perturbation prediction with neural networks
- Explore generative models for single-cell data
:::

## Graph Neural Networks (GNNs)

### Why GNNs for Single-Cell?

- Cells form natural graphs (k-NN, spatial)
- Model cell-cell interactions
- Leverage neighborhood information
- Applicable to spatial transcriptomics

### Cell Graph Construction

```python
import scanpy as sc
import torch
import torch_geometric as tg
from torch_geometric.data import Data

# Build kNN graph
sc.pp.neighbors(adata, n_neighbors=15)

# Convert to PyTorch Geometric format
edge_index = []
for i in range(adata.n_obs):
    neighbors = adata.obsp['connectivities'][i].nonzero()[1]
    for j in neighbors:
        edge_index.append([i, j])

edge_index = torch.LongTensor(edge_index).t()

# Create graph data object
x = torch.FloatTensor(adata.X.toarray())  # Node features
y = torch.LongTensor(adata.obs['cell_type_encoded'].values)  # Labels

graph_data = Data(x=x, edge_index=edge_index, y=y)
```

### GNN Architecture

```python
from torch_geometric.nn import GCNConv, GATConv
import torch.nn as nn
import torch.nn.functional as F

class GCN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.conv3 = GCNConv(hidden_dim, output_dim)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        x = self.conv3(x, edge_index)
        return F.log_softmax(x, dim=1)

# Create model
model = GCN(input_dim=2000, hidden_dim=128, output_dim=10)
```

### Graph Attention Networks (GAT)

```python
class GAT(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, heads=8):
        super().__init__()
        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)
        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)

        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

# Train GAT
gat_model = GAT(input_dim=2000, hidden_dim=64, output_dim=10)
```

### Training GNN

```python
import torch.optim as optim

optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = nn.CrossEntropyLoss()

# Training loop
model.train()
for epoch in range(200):
    optimizer.zero_grad()
    out = model(graph_data.x, graph_data.edge_index)
    loss = criterion(out[train_mask], graph_data.y[train_mask])
    loss.backward()
    optimizer.step()

    if epoch % 20 == 0:
        model.eval()
        with torch.no_grad():
            pred = model(graph_data.x, graph_data.edge_index).argmax(dim=1)
            acc = (pred[test_mask] == graph_data.y[test_mask]).float().mean()
        print(f'Epoch {epoch}, Loss: {loss:.4f}, Acc: {acc:.4f}')
        model.train()
```

## Attention Mechanisms

### Self-Attention for Single-Cell

```python
class AttentionLayer(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.query = nn.Linear(input_dim, hidden_dim)
        self.key = nn.Linear(input_dim, hidden_dim)
        self.value = nn.Linear(input_dim, hidden_dim)
        self.scale = hidden_dim ** 0.5

    def forward(self, x):
        Q = self.query(x)
        K = self.key(x)
        V = self.value(x)

        # Attention scores
        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        attention = F.softmax(scores, dim=-1)

        # Weighted values
        output = torch.matmul(attention, V)
        return output, attention

# Use attention
attention_layer = AttentionLayer(input_dim=2000, hidden_dim=128)
output, attention_weights = attention_layer(X_tensor)
```

## Transformer Architecture

### Single-Cell Transformer

```python
class TransformerEncoder(nn.Module):
    def __init__(self, input_dim, d_model, nhead, num_layers):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        self.pos_encoding = nn.Parameter(torch.randn(1, 5000, d_model))

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model*4,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc = nn.Linear(d_model, 10)  # Output classes

    def forward(self, x):
        # x shape: (batch_size, num_cells, input_dim)
        x = self.embedding(x)
        x = x + self.pos_encoding[:, :x.size(1), :]

        x = self.transformer(x)
        x = x.mean(dim=1)  # Global average pooling
        x = self.fc(x)
        return x

# Create transformer
transformer = TransformerEncoder(
    input_dim=2000,
    d_model=512,
    nhead=8,
    num_layers=6
)
```

## scBERT: Foundation Model

```python
# Using pre-trained scBERT
# (Conceptual - actual implementation may vary)

from transformers import BertModel, BertConfig

# Load pre-trained model
config = BertConfig(
    vocab_size=20000,  # Number of genes
    hidden_size=768,
    num_hidden_layers=12,
    num_attention_heads=12
)

scbert = BertModel(config)

# Fine-tune on your data
# ... (fine-tuning code)

# Extract embeddings
with torch.no_grad():
    embeddings = scbert(input_ids).last_hidden_state

adata.obsm['X_scbert'] = embeddings.mean(dim=1).numpy()
```

## Geneformer: Gene-Expression Foundation Model

```python
# Conceptual usage of Geneformer
# Actual implementation requires specific data format

from geneformer import TranscriptomeTokenizer, GeneformerPretrainer

# Tokenize data
tokenizer = TranscriptomeTokenizer()
tokenized_data = tokenizer.tokenize_data(
    adata,
    output_dir="tokenized_data",
    gene_order="rank"
)

# Load pre-trained model
from transformers import BertForMaskedLM

model = BertForMaskedLM.from_pretrained("geneformer-12L-30M")

# Fine-tune or extract embeddings
# ... (specific to your task)
```

## Perturbation Prediction

### CPA (Compositional Perturbation Autoencoder)

```python
# Conceptual implementation
class PerturbationVAE(nn.Module):
    def __init__(self, gene_dim, latent_dim, perturbation_dim):
        super().__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(gene_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU()
        )

        self.fc_mu = nn.Linear(512, latent_dim)
        self.fc_logvar = nn.Linear(512, latent_dim)

        # Perturbation embedding
        self.pert_embedding = nn.Embedding(100, perturbation_dim)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim + perturbation_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, gene_dim)
        )

    def forward(self, x, perturbation_id):
        # Encode
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)

        # Reparameterize
        z = self.reparameterize(mu, logvar)

        # Get perturbation embedding
        pert_emb = self.pert_embedding(perturbation_id)

        # Decode with perturbation
        z_pert = torch.cat([z, pert_emb], dim=1)
        recon = self.decoder(z_pert)

        return recon, mu, logvar
```

## scGen: Predicting Cellular Responses

```python
# Using scGen for perturbation prediction
from scgen import SCGEN

# Train on control cells
scgen = SCGEN(adata_control, condition_key="condition")
scgen.train(max_epochs=100, batch_size=32, early_stopping=True)

# Predict stimulated cells
predicted_cells = scgen.predict(
    control_key="control",
    stim_key="stimulated",
    cell_type_key="cell_type"
)

# Visualize
sc.pl.umap(predicted_cells, color=['condition', 'cell_type'])
```

## Generative Models

### Conditional VAE for Cell Generation

```python
class ConditionalVAE(nn.Module):
    def __init__(self, input_dim, condition_dim, latent_dim):
        super().__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim + condition_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )

        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_logvar = nn.Linear(256, latent_dim)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim + condition_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, input_dim)
        )

    def encode(self, x, c):
        h = self.encoder(torch.cat([x, c], dim=1))
        return self.fc_mu(h), self.fc_logvar(h)

    def decode(self, z, c):
        return self.decoder(torch.cat([z, c], dim=1))

    def forward(self, x, c):
        mu, logvar = self.encode(x, c)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z, c)
        return recon, mu, logvar

# Generate cells with specific conditions
def generate_cells(model, condition, n_samples=100):
    model.eval()
    with torch.no_grad():
        z = torch.randn(n_samples, latent_dim)
        c = condition.repeat(n_samples, 1)
        generated = model.decode(z, c)
    return generated
```

## Best Practices

::: {.callout-tip}
## Advanced DL Tips

- Use appropriate architectures for your data structure
- Leverage pre-trained models when possible
- Monitor training carefully
- Use validation sets
- Regularize to prevent overfitting
- Consider interpretability
- Validate predictions experimentally
- Share trained models with community
:::

## Model Interpretation

### Attention Visualization

```python
# Visualize attention weights
import matplotlib.pyplot as plt
import seaborn as sns

# Get attention from trained model
_, attention_weights = model(X_tensor)

# Plot attention map
plt.figure(figsize=(10, 8))
sns.heatmap(attention_weights[0].detach().numpy(), cmap='viridis')
plt.title('Attention Weights')
plt.xlabel('Key')
plt.ylabel('Query')
plt.show()
```

### Feature Importance

```python
# Integrated gradients for feature importance
from captum.attr import IntegratedGradients

ig = IntegratedGradients(model)
attributions = ig.attribute(X_tensor, target=target_class)

# Visualize top features
top_features = attributions.abs().mean(dim=0).argsort(descending=True)[:20]
gene_names = adata.var_names[top_features]

plt.barh(range(20), attributions[:, top_features].mean(dim=0).detach())
plt.yticks(range(20), gene_names)
plt.xlabel('Attribution Score')
plt.title('Top Important Genes')
```

## Practical Exercise

::: {.callout-important}
## Hands-On Activity

1. Build a GNN for cell type prediction
2. Implement attention mechanism
3. Fine-tune a transformer model
4. Apply scVI for integration
5. Use scGen for perturbation prediction
6. Visualize attention weights
7. Interpret model predictions
:::

## Challenges and Future Directions

### Current Challenges

- Interpretability of deep models
- Computational resources
- Training data requirements
- Generalization across datasets
- Validation of predictions

### Future Directions

::: {.card}
**Emerging trends**:

- Foundation models for biology
- Multi-modal integration
- Causal modeling
- Spatial graph neural networks
- Few-shot learning for rare cell types
- Explainable AI for biology
:::

## Key Takeaways

- GNNs model cell-cell relationships
- Transformers enable foundation models
- Attention mechanisms provide interpretability
- Perturbation prediction guides experiments
- Pre-trained models accelerate research
- Deep learning is rapidly evolving

## Additional Resources

- [PyTorch Geometric Tutorial](https://pytorch-geometric.readthedocs.io/)
- [scvi-tools Advanced](https://docs.scvi-tools.org/)
- [Geneformer Paper](https://www.nature.com/articles/s41586-023-06139-9)
- [Single-Cell Deep Learning Review](https://www.nature.com/articles/s41592-023-01818-5)

## Course Completion

Congratulations on completing the BRAIN course! You now have comprehensive skills in:

- Neurogenomics and single-cell technologies
- Computational analysis pipelines
- Advanced machine learning and AI methods
- Data interpretation and visualization

::: {.callout-note}
## What's Next?

- Apply these skills to your research
- Contribute to open-source projects
- Stay updated with new methods
- Join the single-cell community
- Share your findings!
:::

---

[‚Üê Back to Module 15](15-deep-learning-part1.qmd) | [Return to Home](../index.qmd) | [View Schedule](../schedule.qmd)

---

::: {.callout-important}
## Certificate and Feedback

Congratulations on completing all modules! Contact us for your certificate of completion and please provide feedback to help us improve the course.
:::
